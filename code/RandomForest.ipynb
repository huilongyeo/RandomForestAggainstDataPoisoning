{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "\n",
    "from sklearn.preprocessing import minmax_scale, OneHotEncoder, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "import mlflow\n",
    "\n",
    "np.random.seed(0)\n",
    "random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 導入訓練資料"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path):\n",
    "    data = pd.read_csv(path)\n",
    "    # drop_list = [\"Label\", \"Flow_ID\", \"Src_IP\", \"Dst_IP\", \"Timestamp\"]\n",
    "    # data = data.drop(drop_list, axis=1)\n",
    "\n",
    "    # y = data[\"Sub_Cat\"]\n",
    "    # X = data.drop([\"Sub_Cat\", \"Cat\"], axis=1)\n",
    "    y = data[\"Cat\"]\n",
    "    X = data.drop([\"Cat\"], axis=1)\n",
    "    column = X.columns\n",
    "     # replace infinnity data by maximum value in float\n",
    "    X = X.replace([np.inf, -np.inf], np.finfo(np.float32).max)\n",
    "    \n",
    "    # Data Normalziation\n",
    "    X = minmax_scale(X, axis=0)\n",
    "    X = pd.DataFrame(X)\n",
    "    X.columns = column\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7, test_size=0.3, random_state=0)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"../data/IoT Network Intrusion Dataset.csv\"\n",
    "path = \"../data/Train_Cat.csv\"\n",
    "\n",
    "X_train, X_test, y_train, y_test= read_data(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42865               Normal\n",
       "91446    MITM ARP Spoofing\n",
       "66374                Mirai\n",
       "79106                  DoS\n",
       "13404               Normal\n",
       "Name: Cat, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建立具有資料投毒攻擊防禦能力的隨機森林\n",
    "\n",
    "隨機森林在訓練模型時會從訓練資料集中隨機抽取資料形成子訓練集，這一步驟稱爲Bagging。Bagging可以避免訓練決策樹的時候造成過擬合，減小模型的方差。子資料集會交由不同的決策樹進行訓練，決策樹會隨機選取資料的特徵作爲決策依據，因此每一顆樹的結構都不同。不同的決策樹會生成不同的預測結果，最後使用投票決定最終的預測結果。  \n",
    "隨機森林進行Bagging的時候，若訓練資料帶有一定比例下的惡意資料，則bagging會將資料可能會將資料分爲帶有惡意資料的自集合和正常資料的子集合，帶有惡意資料的子集合其決策樹也會受影響，受影響的決策樹能夠在投票階段被識別出，最小化惡意資料的影響。\n",
    "\n",
    "使用其他決策方法取代隨機森林，並比較各決策方法的性能與能耗"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "class RandomForest():\n",
    "    def __init__(self, n_estimator=10, max_samples=1.0,\n",
    "                 max_features=1.0, boostrap=True, bootstrap_features=True, random_state=1):\n",
    "\n",
    "        '''\n",
    "        BaggingClassifier:\n",
    "        base_estimator: 決策方法，如Decision Tree, XGBoost等\n",
    "        n_estimators: 評估器個數\n",
    "        max_samples: 從訓練資料集X中抽取的樣本數，用於訓練每個評估器，如果值為int則抽取n個樣本，若爲float則按比例抽取特徵\n",
    "        max_features: 從訓練資料集X中提取用於訓練每個基本評估器的特徵數，同上\n",
    "        bootstrap: 是否放回采樣，如果為False則是passing\n",
    "        bootstrap_features: 是否針對特徵重抽樣\n",
    "        oob_score: 是否使用oob估計汎化誤差\n",
    "        random_state: 隨機種子\n",
    "        n_jobs: 調用CPU内核的數量，默認為1，-1為使用所有内核\n",
    "        '''\n",
    "        base_estimator = DecisionTreeClassifier(random_state=1)\n",
    "        self.classifier = BaggingClassifier(\n",
    "            DecisionTreeClassifier(random_state=1),\n",
    "            n_estimators=n_estimator, max_samples=max_samples,\n",
    "            max_features=max_features, bootstrap=boostrap, bootstrap_features=bootstrap_features,\n",
    "            random_state=random_state, oob_score=True, n_jobs=-1)\n",
    "\n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        self.classifier.fit(X,y)\n",
    "\n",
    "        # # get the loss by out-of-bag score\n",
    "        # oob_score = self.classifier.oob_score_\n",
    "        # print(oob_score)\n",
    "        # return self.loss_values\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.classifier.predict(X)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 使用tensor flow 建具有bagging機制的分類器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trun Warnings off to keep notebook clean\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load module\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.losses import binary_crossentropy\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_classifier():\n",
    "\n",
    "    def __init__(self, number_features, label_mapping, learning_rate=0.003):\n",
    "        # Clear Tensorflow\n",
    "\n",
    "        K.clear_session()\n",
    "        number_label = len(label_mapping)\n",
    "        self.selected_feature = random.sample(range(number_features), number_features//4)\n",
    "\n",
    "        # Define Layers\n",
    "        inputs = layers.Input(shape=(len(self.selected_feature), ))\n",
    "        dropout_0 = layers.Dropout(0.2)(inputs) # 正規化\n",
    "\n",
    "        dense_1 = layers.Dense(240, activation='relu')(dropout_0)\n",
    "        dropout_1 = layers.Dropout(0.2)(dense_1)\n",
    "\n",
    "        dense_2 = layers.Dense(50, activation='relu')(dropout_1)\n",
    "        dropout_2 = layers.Dropout(0.2)(dense_2)\n",
    "\n",
    "        outputs = layers.Dense(number_label, activation=\"softmax\")(dropout_2)\n",
    "\n",
    "        self.net = Model(inputs, outputs)\n",
    "        self.label_mapping = label_mapping\n",
    "\n",
    "        # compile model\n",
    "        opt = Adam(learning_rate=learning_rate)\n",
    "        self.net.compile(loss='categorical_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "\n",
    "        self.encoder = LabelEncoder()\n",
    "    \n",
    "    def fit(self, X, y, epochs = 10, batch_size=32, verbose=1):\n",
    "        integers_labels = [self.label_mapping[label] for label in y]\n",
    "        y = to_categorical(integers_labels, num_classes=len(self.label_mapping))\n",
    "\n",
    "        random_feature = X.iloc[:,self.selected_feature]\n",
    "\n",
    "        return self.net.fit(random_feature,y,epochs=epochs, batch_size=batch_size, verbose=verbose)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        random_feature = X.iloc[:,self.selected_feature]\n",
    "        predict = self.net.predict(random_feature, verbose=None)\n",
    "        mapping = {v: k for k, v in self.label_mapping.items()}\n",
    "        predict_int =  np.argmax(predict, axis=-1)\n",
    "        return np.vectorize(mapping.get)(predict_int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = list(y_train.unique())\n",
    "lable_mapping = {label: idx for idx, label in enumerate(l)}\n",
    "\n",
    "number_features = X_train.shape[1]\n",
    "model = MLP_classifier(number_features=number_features, label_mapping=lable_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.history.History at 0x1e6936ba510>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X_train, y_train, epochs=1, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7198333333333333\n"
     ]
    }
   ],
   "source": [
    "predict = model.predict(X_test)\n",
    "print(accuracy_score(y_test, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "              DoS       0.92      0.97      0.94      3721\n",
      "MITM ARP Spoofing       0.40      0.87      0.55      3771\n",
      "            Mirai       0.91      0.35      0.51      3794\n",
      "           Normal       0.81      0.90      0.85     14909\n",
      "             Scan       0.00      0.00      0.00      3805\n",
      "\n",
      "         accuracy                           0.72     30000\n",
      "        macro avg       0.61      0.62      0.57     30000\n",
      "     weighted avg       0.68      0.72      0.67     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Random_Forest():\n",
    "\n",
    "    def __init__(self, number_of_nets=10, learning_rate=0.003):\n",
    "        self.number_of_nets = number_of_nets\n",
    "        self.models = []\n",
    "        self.learning_rate = learning_rate\n",
    "        self.label_mapping = {}\n",
    "    \n",
    "    def fit(self, X, y, epochs = 10, batch_size=32, verbose=1):\n",
    "        training_set_size = len(X)\n",
    "        sample_size = training_set_size // 10\n",
    "        number_features = X.shape[1]\n",
    "\n",
    "        # get the lable mapping\n",
    "        label_list = list(y.unique())\n",
    "        self.label_mapping = {label: idx for idx, label in enumerate(label_list)}\n",
    "\n",
    "        for i in range(self.number_of_nets):\n",
    "            print(f'Training model {i+1} of {self.number_of_nets}')\n",
    "            model = MLP_classifier(number_features=number_features, label_mapping=self.label_mapping, learning_rate=self.learning_rate)\n",
    "            # Get samples of training data\n",
    "            indexes = np.random.choice(range(training_set_size), sample_size)\n",
    "            resample_X = X.iloc[indexes]\n",
    "            resample_y = y.iloc[indexes]\n",
    "\n",
    "            model.fit(resample_X, resample_y, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "            self.models.append(model)\n",
    "\n",
    "    def predict(self, X):\n",
    "        predicts = []\n",
    "        for model in self.models:\n",
    "            predict = model.predict(X)\n",
    "            predicts.append(predict)\n",
    "        final_predict = []\n",
    "        for i in range(len(X)):\n",
    "            votes = [pred[i] for pred in predicts]\n",
    "            majority_vote = Counter(votes).most_common(1)[0][0]\n",
    "            final_predict.append(majority_vote)\n",
    "\n",
    "        return final_predict\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 訓練隨機森林\n",
    "使用經過處理的訓練資料對隨機森林進行訓練, 期間使用MLFlow記錄模型的訓練過程"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/04/07 22:00:24 WARNING mlflow.utils.autologging_utils: You are using an unsupported version of tensorflow. If you encounter errors during autologging, try upgrading / downgrading tensorflow to a supported version, or try upgrading MLflow.\n"
     ]
    }
   ],
   "source": [
    "mlflow.tensorflow.autolog(checkpoint=True, checkpoint_save_best_only=False)\n",
    "\n",
    "model = Random_Forest(number_of_nets=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/04/07 22:00:27 WARNING mlflow.tensorflow: Unrecognized dataset type <class 'pandas.core.frame.DataFrame'>. Dataset logging skipped.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model 1 of 1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n",
      "2024/04/07 22:00:29 WARNING mlflow.tensorflow: Failed to infer model signature: could not sample data to infer model signature: Cannot log input example or model signature for input with type <class 'pandas.core.frame.DataFrame'>. TensorFlow Keras autologging can only log input examples and model signatures for the following input types: numpy.ndarray, dict[string -> numpy.ndarray], tensorflow.keras.utils.Sequence, and tensorflow.data.Dataset (TensorFlow >= 2.1.0 required)\n",
      "2024/04/07 22:00:29 WARNING mlflow.tensorflow: You are saving a TensorFlow Core model or Keras model without a signature. Inference with mlflow.pyfunc.spark_udf() will not work unless the model's pyfunc representation accepts pandas DataFrames as inference inputs.\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run() as run:\n",
    "    model.fit(X_train, y_train, epochs=1, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6601333333333333\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   precision    recall  f1-score   support\n",
      "\n",
      "              DoS       0.96      0.95      0.95      3721\n",
      "MITM ARP Spoofing       0.00      0.00      0.00      3771\n",
      "            Mirai       0.65      0.40      0.49      3794\n",
      "           Normal       0.62      0.99      0.76     14909\n",
      "             Scan       0.00      0.00      0.00      3805\n",
      "\n",
      "         accuracy                           0.66     30000\n",
      "        macro avg       0.45      0.47      0.44     30000\n",
      "     weighted avg       0.51      0.66      0.56     30000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predict))\n",
    "mlflow.end_run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "Run with UUID ebaa0c186f4d455198c516ac7d62b30f is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m mlflow\u001b[38;5;241m.\u001b[39msklearn\u001b[38;5;241m.\u001b[39mautolog()\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDecisionTreeClassifier\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m run:\n\u001b[0;32m      4\u001b[0m     rf \u001b[38;5;241m=\u001b[39m RandomForest()\n\u001b[0;32m      5\u001b[0m     rf\u001b[38;5;241m.\u001b[39mfit(X_train, y_train)\n",
      "File \u001b[1;32mc:\\Users\\chuil\\桌面\\Project\\Random Forest\\venv\\Lib\\site-packages\\mlflow\\tracking\\fluent.py:305\u001b[0m, in \u001b[0;36mstart_run\u001b[1;34m(run_id, experiment_id, run_name, nested, tags, description, log_system_metrics)\u001b[0m\n\u001b[0;32m    303\u001b[0m experiment_id \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(experiment_id) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(experiment_id, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m experiment_id\n\u001b[0;32m    304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(_active_run_stack) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m nested:\n\u001b[1;32m--> 305\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\n\u001b[0;32m    306\u001b[0m         (\n\u001b[0;32m    307\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRun with UUID \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m is already active. To start a new run, first end the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    308\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcurrent run with mlflow.end_run(). To start a nested \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    309\u001b[0m             \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun, call start_run with nested=True\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    310\u001b[0m         )\u001b[38;5;241m.\u001b[39mformat(_active_run_stack[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39minfo\u001b[38;5;241m.\u001b[39mrun_id)\n\u001b[0;32m    311\u001b[0m     )\n\u001b[0;32m    312\u001b[0m client \u001b[38;5;241m=\u001b[39m MlflowClient()\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m run_id:\n",
      "\u001b[1;31mException\u001b[0m: Run with UUID ebaa0c186f4d455198c516ac7d62b30f is already active. To start a new run, first end the current run with mlflow.end_run(). To start a nested run, call start_run with nested=True"
     ]
    }
   ],
   "source": [
    "mlflow.sklearn.autolog()\n",
    "\n",
    "with mlflow.start_run(run_name=\"DecisionTreeClassifier\") as run:\n",
    "    rf = RandomForest()\n",
    "    rf.fit(X_train, y_train)\n",
    "    mt.accuracy_score(y_test, rf.predict(X_test))\n",
    "    \n",
    "mlflow.end_run()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/04/01 19:06:29 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\chuil\\桌面\\Project\\Random Forest\\venv\\Lib\\site-packages\\mlflow\\data\\digest_utils.py:26: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Accuracy: 82.2515%\n"
     ]
    }
   ],
   "source": [
    "train_predict = rf.predict(X_train)\n",
    "\n",
    "accuracy_train = mt.accuracy_score(y_train, train_predict)\n",
    "\n",
    "mlflow.log_metric(\"accuracy_train\", accuracy_train*100)\n",
    "\n",
    "print(\"Train Accuracy: {:.4f}%\".format(accuracy_train * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "      DoS-Synflooding       1.00      1.00      1.00     41639\n",
      "    MITM ARP Spoofing       0.99      0.99      0.99     24867\n",
      "    Mirai-Ackflooding       0.40      0.39      0.40     38601\n",
      "  Mirai-HTTP Flooding       0.41      0.40      0.41     39152\n",
      "Mirai-Hostbruteforceg       0.95      0.98      0.96     84951\n",
      "   Mirai-UDP Flooding       0.82      0.82      0.82    128339\n",
      "               Normal       1.00      1.00      1.00     27914\n",
      "        Scan Hostport       0.92      0.69      0.79     15506\n",
      "         Scan Port OS       0.88      0.97      0.93     37079\n",
      "\n",
      "             accuracy                           0.82    438048\n",
      "            macro avg       0.82      0.81      0.81    438048\n",
      "         weighted avg       0.82      0.82      0.82    438048\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_train, train_predict))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "使用測試資料集驗證模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/04/01 19:07:09 WARNING mlflow.utils.autologging_utils: MLflow autologging encountered a warning: \"c:\\Users\\chuil\\桌面\\Project\\Random Forest\\venv\\Lib\\site-packages\\mlflow\\data\\digest_utils.py:26: FutureWarning: DataFrame.applymap has been deprecated. Use DataFrame.map instead.\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 75.8143%\n"
     ]
    }
   ],
   "source": [
    "test_predict = rf.predict(X_test)\n",
    "\n",
    "accuracy_test = mt.accuracy_score(y_test, test_predict)\n",
    "\n",
    "print(\"Test Accuracy: {:.4f}%\".format(accuracy_test * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       precision    recall  f1-score   support\n",
      "\n",
      "      DoS-Synflooding       1.00      1.00      1.00     17752\n",
      "    MITM ARP Spoofing       0.97      0.97      0.97     10510\n",
      "    Mirai-Ackflooding       0.18      0.17      0.18     16523\n",
      "  Mirai-HTTP Flooding       0.19      0.19      0.19     16666\n",
      "Mirai-Hostbruteforceg       0.93      0.98      0.95     36230\n",
      "   Mirai-UDP Flooding       0.76      0.75      0.76     55215\n",
      "               Normal       1.00      0.99      1.00     12159\n",
      "        Scan Hostport       0.86      0.62      0.72      6686\n",
      "         Scan Port OS       0.86      0.95      0.90     15994\n",
      "\n",
      "             accuracy                           0.76    187735\n",
      "            macro avg       0.75      0.74      0.74    187735\n",
      "         weighted avg       0.75      0.76      0.76    187735\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, test_predict))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
